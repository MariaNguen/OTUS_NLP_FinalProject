{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256725af",
   "metadata": {},
   "source": [
    "# RuGPT3: инференс и валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8549a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Инференс\" data-toc-modified-id=\"Инференс-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Инференс</a></span></li><li><span><a href=\"#Оценка\" data-toc-modified-id=\"Оценка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Оценка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Style-Transfer-Accuracy-(STA)\" data-toc-modified-id=\"Style-Transfer-Accuracy-(STA)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Style Transfer Accuracy (STA)</a></span></li><li><span><a href=\"#Meaning-Preservation-Score-(SIM)\" data-toc-modified-id=\"Meaning-Preservation-Score-(SIM)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Meaning Preservation Score (SIM)</a></span></li><li><span><a href=\"#Fluency-Score-(Fl)\" data-toc-modified-id=\"Fluency-Score-(Fl)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Fluency Score (Fl)</a></span></li><li><span><a href=\"#Joint-Score-(J)\" data-toc-modified-id=\"Joint-Score-(J)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Joint Score (J)</a></span></li><li><span><a href=\"#ChrF1-with-references\" data-toc-modified-id=\"ChrF1-with-references-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>ChrF1 with references</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d733a",
   "metadata": {},
   "source": [
    "## Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bbd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb3dbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5efe861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"./model_ruT5_5e-5_noEDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983e0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase(text, model, n=None, max_length='auto', temperature=0.0, beams=3):\n",
    "    texts = [text] if isinstance(text, str) else text\n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True)['input_ids'].to(model.device)\n",
    "    if max_length == 'auto':\n",
    "        max_length = int(inputs.shape[1] * 1.2) + 10\n",
    "    result = model.generate(\n",
    "        inputs,\n",
    "        num_return_sequences=n or 1,\n",
    "        do_sample=False,\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=3.0,\n",
    "        max_length=max_length,\n",
    "        bad_words_ids=[[2]],  # unk\n",
    "        num_beams=beams,\n",
    "    )\n",
    "    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n",
    "    if not n and isinstance(text, str):\n",
    "        return texts[0]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc05c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ff7ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv('../content/dev.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c031cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_inputs = list(dev['toxic_comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb5c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3883e3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fb4d8f47e424d99ea632bf4986694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "para_results = []\n",
    "problematic_batch = [] #if something goes wrong you can track such bathces\n",
    "batch_size = 8\n",
    "\n",
    "for i in tqdm(range(0, len(toxic_inputs), batch_size)):\n",
    "    batch = [sentence for sentence in toxic_inputs[i:i + batch_size]]\n",
    "    try:\n",
    "        para_results.extend(paraphrase(batch, model, temperature=0.0))\n",
    "    except Exception as e:\n",
    "        print(i, e)\n",
    "        para_results.append(toxic_inputs[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270ec6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ruT5_noEDA_dev.txt', 'w') as file:\n",
    "    file.writelines([sentence+'\\n' for sentence in para_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a68334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def cleanup():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcc1e4",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22a8072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c00072c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name=None, model=None, tokenizer=None,\n",
    "               model_class=AutoModelForSequenceClassification, use_cuda=True):\n",
    "    if model is None:\n",
    "        if model_name is None:\n",
    "            raise ValueError('Either model or model_name should be provided')\n",
    "        model = model_class.from_pretrained(model_name)\n",
    "        if torch.cuda.is_available() and use_cuda:\n",
    "            model.cuda()\n",
    "    if tokenizer is None:\n",
    "        if model_name is None:\n",
    "            raise ValueError('Either tokenizer or model_name should be provided')\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db0167",
   "metadata": {},
   "source": [
    "### Style Transfer Accuracy (STA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f807b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_target_label(model, target_label):\n",
    "    if target_label in model.config.id2label:\n",
    "        pass\n",
    "    elif target_label in model.config.label2id:\n",
    "        target_label = model.config.label2id.get(target_label)\n",
    "    elif target_label.isnumeric() and int(target_label) in model.config.id2label:\n",
    "        target_label = int(target_label)\n",
    "    else:\n",
    "        raise ValueError(f'target_label \"{target_label}\" is not in model labels or ids: {model.config.id2label}.')\n",
    "    return target_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "991f45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_texts(model, tokenizer, texts, second_texts=None, target_label=None, batch_size=32, verbose=False):\n",
    "    target_label = prepare_target_label(model, target_label)\n",
    "    res = []\n",
    "    if verbose:\n",
    "        tq = trange\n",
    "    else:\n",
    "        tq = range\n",
    "    for i in tq(0, len(texts), batch_size):\n",
    "        inputs = [texts[i:i+batch_size]]\n",
    "        if second_texts is not None:\n",
    "            inputs.append(second_texts[i:i+batch_size])\n",
    "        inputs = tokenizer(*inputs, return_tensors='pt', padding=True, truncation=True, max_length=512).to(model.device)\n",
    "        with torch.no_grad():\n",
    "            preds = torch.softmax(model(**inputs).logits, -1)[:, target_label].cpu().numpy()\n",
    "        res.append(preds)\n",
    "    return np.concatenate(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f47b68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_calibration(data, coef=1.0, px=1, py=1, minimum=0, maximum=1):\n",
    "    result = (data - px) * coef + py\n",
    "    if minimum is not None:\n",
    "        result = np.maximum(minimum, result)\n",
    "    if maximum is not None:\n",
    "        result = np.minimum(maximum, result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66f00074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_style(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    texts,\n",
    "    target_label=1,  # 1 is toxic, 0 is neutral\n",
    "    batch_size=32,\n",
    "    verbose=False\n",
    "):\n",
    "    target_label = prepare_target_label(model, target_label)\n",
    "    scores = classify_texts(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        texts,\n",
    "        batch_size=batch_size, verbose=verbose, target_label=target_label\n",
    "    )\n",
    "    return rotation_calibration(scores, 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f8a9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_model, style_tokenizer = load_model('SkolkovoInstitute/russian_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27d4884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8bbe38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ad6190c1614a6dad31d18ca590e2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style transfer accuracy (STA):  0.7745540738105774\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate_style(\n",
    "    model = style_model,\n",
    "    tokenizer = style_tokenizer,\n",
    "    texts = para_results,\n",
    "    target_label=0,  # 1 is toxic, 0 is neutral\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "print(f'Style transfer accuracy (STA):  {np.mean(accuracy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1bb68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2a9ad",
   "metadata": {},
   "source": [
    "### Meaning Preservation Score (SIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "771925ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cls(texts, model, tokenizer, batch_size=32, verbose=False):\n",
    "    results = []\n",
    "    if verbose:\n",
    "        tq = trange\n",
    "    else:\n",
    "        tq = range\n",
    "    for i in tq(0, len(texts), batch_size):\n",
    "        batch = texts[i: i + batch_size]\n",
    "        with torch.no_grad():\n",
    "            out = model(**tokenizer(batch, return_tensors='pt', padding=True, truncation=True).to(model.device))\n",
    "            embeddings = out.pooler_output\n",
    "            embeddings = torch.nn.functional.normalize(embeddings).cpu().numpy()\n",
    "            results.append(embeddings)\n",
    "    return np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4bfffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cosine_similarity(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    original_texts,\n",
    "    rewritten_texts,\n",
    "    batch_size=32,\n",
    "    verbose=False,\n",
    "):\n",
    "    scores = (\n",
    "        encode_cls(original_texts, model=model, tokenizer=tokenizer, batch_size=batch_size, verbose=verbose)\n",
    "        * encode_cls(rewritten_texts, model=model, tokenizer=tokenizer, batch_size=batch_size, verbose=verbose)\n",
    "    ).sum(1)\n",
    "    return rotation_calibration(scores, 1.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "651e966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meaning_model, meaning_tokenizer = load_model('cointegrated/LaBSE-en-ru', model_class=AutoModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22af5c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848e9853c555498f9b3e1c290426414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e2e7495141425bb4436409633a7585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meaning preservation (SIM):  0.7804124355316162\n"
     ]
    }
   ],
   "source": [
    "similarity = evaluate_cosine_similarity(\n",
    "    model = meaning_model,\n",
    "    tokenizer = meaning_tokenizer,\n",
    "    original_texts = list(toxic_inputs),\n",
    "    rewritten_texts = para_results,\n",
    "    batch_size=32,\n",
    "    verbose=True,\n",
    "    )\n",
    "print(f'Meaning preservation (SIM):  {np.mean(similarity)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba5aaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083355f",
   "metadata": {},
   "source": [
    "### Fluency Score (Fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55caf1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cola_relative(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    original_texts,\n",
    "    rewritten_texts,\n",
    "    target_label=1,\n",
    "    batch_size=32,\n",
    "    verbose=False,\n",
    "    maximum=0,\n",
    "):\n",
    "    target_label = prepare_target_label(model, target_label)\n",
    "    original_scores = classify_texts(\n",
    "        model, tokenizer,\n",
    "        original_texts,\n",
    "        batch_size=batch_size, verbose=verbose, target_label=target_label\n",
    "    )\n",
    "    rewritten_scores = classify_texts(\n",
    "        model, tokenizer,\n",
    "        rewritten_texts,\n",
    "        batch_size=batch_size, verbose=verbose, target_label=target_label\n",
    "    )\n",
    "    scores = rewritten_scores - original_scores\n",
    "    if maximum is not None:\n",
    "        scores = np.minimum(0, scores)\n",
    "    return rotation_calibration(scores, 1.15, px=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0797eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_model, cola_tolenizer = load_model('SkolkovoInstitute/rubert-base-corruption-detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc206d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e841cde5f5dd4124aa46127394d24a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b975fc30885458a9329f125424def72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluency score (FL):  0.803834080696106\n"
     ]
    }
   ],
   "source": [
    "fluency = evaluate_cola_relative(\n",
    "    model = cola_model,\n",
    "    tokenizer = cola_tolenizer,\n",
    "    original_texts = list(toxic_inputs),\n",
    "    rewritten_texts = para_results,\n",
    "    target_label=1,\n",
    "    batch_size=32,\n",
    "    verbose=True\n",
    ")\n",
    "print(f'Fluency score (FL):  {np.mean(fluency)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "116978f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb6968",
   "metadata": {},
   "source": [
    "### Joint Score (J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e6ae096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint score (J):   0.4970993101596832\n"
     ]
    }
   ],
   "source": [
    "joint = accuracy * similarity * fluency\n",
    "print(f'Joint score (J):   {np.mean(joint)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ce636",
   "metadata": {},
   "source": [
    "### ChrF1 with references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17556f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.chrf_score import corpus_chrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dev.fillna('')\n",
    "neutral_references = []\n",
    "for index, row in df.iterrows():\n",
    "    neutral_references.append([row['neutral_comment1'], row['neutral_comment2'], row['neutral_comment3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f29ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_chrf(neutral_references, para_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a8373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
